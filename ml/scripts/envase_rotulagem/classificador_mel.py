"""
CLASSIFICADOR DE PROBABILIDADE DE FALHAS - PRODU√á√ÉO DE MEL
===========================================================
Script principal focado nas 5 responsabilidades essenciais:
1. Escolha e carregamento da base de dados
2. Treinamento/Valida√ß√£o  
3. Teste
4. Exibi√ß√£o de Resultados
5. Mostrar gr√°ficos/superf√≠cie de decis√£o
"""

import pandas as pd
import joblib
import os
import sys
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.svm import SVC
from sklearn.linear_model import LogisticRegression
from sklearn.naive_bayes import GaussianNB
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
import warnings
warnings.filterwarnings('ignore')

# Classes de probabilidade
CLASSES = ['DESPREZ√çVEL', 'BAIXA', 'M√âDIA', 'ALTA']

def carregar_dataset():
    """1. CARREGAMENTO DA BASE DE DADOS - ENVASE E ROTULAGEM"""
    print("üçØ CLASSIFICADOR DE MEL - Envase e Rotulagem")
    print("=" * 60)
    
    # Determinar caminho absoluto baseado na localiza√ß√£o do script
    script_dir = os.path.dirname(os.path.abspath(__file__))
    ml_dir = os.path.join(script_dir, "..", "..")
    caminho = os.path.join(ml_dir, "dataset", "mel", "envase_rotulagem", "dataset_envase_rotulagem.csv")
    nome = "Envase e Rotulagem"
    
    # Verificar se arquivo existe
    if not os.path.exists(caminho):
        print(f"‚ùå Dataset n√£o encontrado: {caminho}")
        print("\nüîß Gerando dataset...")
        try:
            # Adicionar view_generators ao path
            view_generators_path = os.path.join(ml_dir, "view_generators")
            if view_generators_path not in sys.path:
                sys.path.insert(0, view_generators_path)
            
            from view_generators.dataset_generator import gerar_dataset_por_tipo
            caminho, _ = gerar_dataset_por_tipo('envase_rotulagem', 1500)
            nome = "Envase e Rotulagem (Gerado)"
        except Exception as e:
            print(f"‚ùå Erro ao gerar dataset: {e}")
            return None, None
    
    # Carregar dataset
    try:
        df = pd.read_csv(caminho)
        print(f"‚úÖ Dataset carregado: {nome}")
        print(f"üìä {len(df)} amostras, {len(df.columns)-1} atributos")
        
        # Verificar se tem coluna target
        if 'probabilidade' not in df.columns:
            print("‚ùå Coluna 'probabilidade' n√£o encontrada no dataset")
            return None, None
            
        return df, nome
        
    except Exception as e:
        print(f"‚ùå Erro ao carregar dataset: {e}")
        return None, None


def escolher_algoritmo():
    """Permite ao usu√°rio escolher o algoritmo de ML"""
    print("\nü§ñ ESCOLHA DO ALGORITMO DE MACHINE LEARNING")
    print("=" * 50)
    
    algoritmos = {
        '1': {
            'nome': 'Random Forest',
            'modelo': RandomForestClassifier(
                n_estimators=100,
                max_depth=10,
                min_samples_split=5,
                random_state=42,
                n_jobs=-1
            ),
            'descricao': 'Ensemble de √°rvores de decis√£o (Recomendado)'
        },
        '2': {
            'nome': 'Gradient Boosting',
            'modelo': GradientBoostingClassifier(
                n_estimators=100,
                max_depth=6,
                learning_rate=0.1,
                random_state=42
            ),
            'descricao': 'Boosting sequencial de modelos fracos'
        },
        '3': {
            'nome': 'SVM',
            'modelo': SVC(
                C=1.0,
                kernel='linear',
                random_state=42,
                probability=True
            ),
            'descricao': 'Support Vector Machine com kernel Linear'
        },
        '4': {
            'nome': 'Regress√£o Log√≠stica',
            'modelo': LogisticRegression(
                max_iter=1000,
                random_state=42,
                multi_class='ovr'
            ),
            'descricao': 'Modelo linear para classifica√ß√£o'
        },
        '5': {
            'nome': 'Naive Bayes',
            'modelo': GaussianNB(),
            'descricao': 'Classificador probabil√≠stico baseado em Bayes'
        }
    }
    
    print("Algoritmos dispon√≠veis:")
    for key, info in algoritmos.items():
        print(f"{key}. {info['nome']:<20} - {info['descricao']}")
    
    while True:
        escolha = input(f"\nEscolha um algoritmo (1-5): ").strip()
        
        if escolha in algoritmos:
            algoritmo_info = algoritmos[escolha]
            print(f"\n‚úÖ Algoritmo selecionado: {algoritmo_info['nome']}")
            return algoritmo_info['modelo'], algoritmo_info['nome']
        else:
            print("‚ùå Op√ß√£o inv√°lida! Digite um n√∫mero de 1 a 5.")

def treinar_validar_modelo(X_train, y_train, modelo, nome_algoritmo):
    """2. TREINAMENTO/VALIDA√á√ÉO"""
    print("\nü§ñ TREINAMENTO DO MODELO")
    print("=" * 30)
    
    print(f"üîß Treinando {nome_algoritmo}...")
    modelo.fit(X_train, y_train)
    
    # Valida√ß√£o cruzada simples
    from sklearn.model_selection import cross_val_score
    cv_scores = cross_val_score(modelo, X_train, y_train, cv=5)
    
    print(f"‚úÖ Modelo treinado")
    print(f"üìä Valida√ß√£o cruzada: {cv_scores.mean():.3f} (+/- {cv_scores.std() * 2:.3f})")
    
    return modelo


def testar_modelo(modelo, X_test, y_test):
    """3. TESTE"""
    print("\nüéØ TESTE DO MODELO")
    print("=" * 20)
    
    # Fazer predi√ß√µes
    y_pred = modelo.predict(X_test)
    
    # Calcular m√©tricas
    accuracy = accuracy_score(y_test, y_pred)
    
    print(f"üéØ Acur√°cia: {accuracy:.3f}")
    
    return y_pred, accuracy


def exibir_resultados(y_test, y_pred, accuracy, modelo, nome_algoritmo):
    """4. EXIBI√á√ÉO DE RESULTADOS"""
    print("\nüìã RESULTADOS DETALHADOS")
    print("=" * 40)
    
    print(f"\nü§ñ Classificador: {nome_algoritmo}")
    
    # Mostrar par√¢metros espec√≠ficos do modelo
    if isinstance(modelo, RandomForestClassifier):
        print(f"   - Estimadores: {modelo.n_estimators}")
        print(f"   - Max Depth: {modelo.max_depth}")
        print(f"   - Min Samples Split: {modelo.min_samples_split}")
    elif isinstance(modelo, GradientBoostingClassifier):
        print(f"   - Estimadores: {modelo.n_estimators}")
        print(f"   - Max Depth: {modelo.max_depth}")
        print(f"   - Learning Rate: {modelo.learning_rate}")
    elif isinstance(modelo, SVC):
        print(f"   - Kernel: {modelo.kernel}")
        print(f"   - C: {modelo.C}")
        print(f"   - Gamma: {modelo.gamma}")
    elif isinstance(modelo, LogisticRegression):
        print(f"   - Max Iterations: {modelo.max_iter}")
        print(f"   - Multi Class: {modelo.multi_class}")
    elif isinstance(modelo, GaussianNB):
        print(f"   - Var Smoothing: {modelo.var_smoothing}")
    
    print(f"\nüéØ Acur√°cia Geral: {accuracy:.1%}")
    
    # Relat√≥rio de classifica√ß√£o
    print(f"\nüìä M√©tricas por Classe:")
    print(classification_report(y_test, y_pred, target_names=CLASSES))
    
    # Matriz de confus√£o
    print(f"\nüîç Matriz de Confus√£o:")
    cm = confusion_matrix(y_test, y_pred)
    
    print("       Predito ‚Üí")
    print("Real ‚Üì  ", end="")
    for classe in ['DESP', 'BAIX', 'MED', 'ALTA']:
        print(f"{classe:>6}", end="")
    print()
    
    class_labels = ['DESP', 'BAIX', 'MED', 'ALTA']
    for i, row in enumerate(cm):
        print(f"{class_labels[i]:<6} ", end="")
        for val in row:
            print(f"{val:>6}", end="")
        print()




def salvar_resultados_treinamento(y_test, y_pred, accuracy, nome_dataset):
    """Salva os resultados do treinamento em arquivo texto"""
    timestamp = pd.Timestamp.now().strftime("%Y%m%d_%H%M%S")
    
    # Determinar subpasta baseada no nome do dataset
    subpasta = "envase_rotulagem"
    
    # Criar pasta se n√£o existir (caminho absoluto)
    script_dir = os.path.dirname(os.path.abspath(__file__))
    ml_dir = os.path.join(script_dir, "..", "..")
    pasta_results = os.path.join(ml_dir, "results", subpasta)
    os.makedirs(pasta_results, exist_ok=True)
    
    # Criar relat√≥rio de resultados
    nome_arquivo = f"resultados_treinamento_{nome_dataset.lower().replace(' ', '_')}_{timestamp}.txt"
    caminho_arquivo = os.path.join(pasta_results, nome_arquivo)
    
    with open(caminho_arquivo, 'w', encoding='utf-8') as f:
        f.write(f"RESULTADOS DO TREINAMENTO - {nome_dataset.upper()}\n")
        f.write("=" * 60 + "\n\n")
        f.write(f"Timestamp: {timestamp}\n")
        f.write(f"Dataset: {nome_dataset}\n\n")
        f.write(f"CLASSIFICADOR UTILIZADO:\n")
        f.write(f"- Algoritmo: Random Forest\n")
        f.write(f"- Estimadores: 100\n")
        f.write(f"- Max Depth: 10\n")
        f.write(f"- Min Samples Split: 5\n")
        f.write(f"- Random State: 42\n\n")
        f.write(f"RESULTADOS:\n")
        f.write(f"Acur√°cia: {accuracy:.1%}\n\n")
        
        # Relat√≥rio de classifica√ß√£o
        f.write("M√âTRICAS POR CLASSE:\n")
        f.write("-" * 30 + "\n")
        from sklearn.metrics import classification_report
        report = classification_report(y_test, y_pred, target_names=CLASSES)
        f.write(report + "\n\n")
        
        # Matriz de confus√£o
        f.write("MATRIZ DE CONFUS√ÉO:\n")
        f.write("-" * 20 + "\n")
        from sklearn.metrics import confusion_matrix
        cm = confusion_matrix(y_test, y_pred)
        
        f.write("       Predito ‚Üí\n")
        f.write("Real ‚Üì  ")
        for classe in ['DESP', 'BAIX', 'MED', 'ALTA']:
            f.write(f"{classe:>6}")
        f.write("\n")
        
        class_labels = ['DESP', 'BAIX', 'MED', 'ALTA']
        for i, row in enumerate(cm):
            f.write(f"{class_labels[i]:<6} ")
            for val in row:
                f.write(f"{val:>6}")
            f.write("\n")
    
    print(f"üìã Resultados salvos: {caminho_arquivo}")
    return caminho_arquivo


def salvar_modelo_final(modelo, scaler, nome_dataset):
    """Salva o modelo treinado na subpasta apropriada"""
    timestamp = pd.Timestamp.now().strftime("%Y%m%d_%H%M%S")
    
    # Determinar subpasta baseada no nome do dataset
    subpasta = "envase_rotulagem"
    
    # Criar pasta se n√£o existir (caminho absoluto)
    script_dir = os.path.dirname(os.path.abspath(__file__))
    ml_dir = os.path.join(script_dir, "..", "..")
    pasta_modelo = os.path.join(ml_dir, "models", subpasta)
    os.makedirs(pasta_modelo, exist_ok=True)
    
    # Salvar modelo
    modelo_path = f"{pasta_modelo}/classificador_mel_{timestamp}.pkl"
    joblib.dump(modelo, modelo_path)
    
    # Salvar scaler
    scaler_path = f"{pasta_modelo}/scaler_mel_{timestamp}.pkl"
    joblib.dump(scaler, scaler_path)
    
    # Salvar configura√ß√£o
    config = {
        'dataset_usado': nome_dataset,
        'timestamp': timestamp,
        'classes': CLASSES,
        'modelo_path': modelo_path,
        'scaler_path': scaler_path,
        'etapa': subpasta
    }
    
    import json
    config_path = f"{pasta_modelo}/config_classificador_{timestamp}.json"
    with open(config_path, 'w') as f:
        json.dump(config, f, indent=2)
    
    print(f"\nüíæ MODELO SALVO em {subpasta}:")
    print(f"  üìÅ Modelo: {modelo_path}")
    print(f"  üìÅ Scaler: {scaler_path}")
    print(f"  üìÅ Config: {config_path}")
    
    return modelo_path, scaler_path, config_path


def main():
    """Fun√ß√£o principal - Pipeline das 5 responsabilidades"""
    print("üçØ CLASSIFICADOR DE PROBABILIDADE DE FALHAS - MEL")
    print("=" * 60)
    print("Sistema focado nas 5 responsabilidades essenciais\n")
    
    # 1. CARREGAMENTO DA BASE DE DADOS
    df, nome_dataset = carregar_dataset()
    
    if df is None:
        return
    
    # Preparar dados
    X = df.drop('probabilidade', axis=1)
    y = df['probabilidade']
    
    print(f"\nüîß Preparando dados...")
    print(f"üìä Features: {list(X.columns)}")
    print(f"üéØ Classes: {CLASSES}")
    
    # Dividir dados
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42, stratify=y
    )
    
    # Normalizar
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_test_scaled = scaler.transform(X_test)
    
    print(f"‚úÖ Divis√£o: {len(X_train)} treino, {len(X_test)} teste")
    
    # 1.5. ESCOLHA DO ALGORITMO
    modelo, nome_algoritmo = escolher_algoritmo()
    
    # 2. TREINAMENTO/VALIDA√á√ÉO
    modelo = treinar_validar_modelo(X_train_scaled, y_train, modelo, nome_algoritmo)
    
    # 3. TESTE
    y_pred, accuracy = testar_modelo(modelo, X_test_scaled, y_test)
    
    # 4. EXIBI√á√ÉO DE RESULTADOS
    exibir_resultados(y_test, y_pred, accuracy, modelo, nome_algoritmo)
    
    # 5. MOSTRAR GR√ÅFICOS E AN√ÅLISES
    try:
        import sys
        # Adicionar view_generators ao path
        ml_dir = os.path.join(os.path.dirname(os.path.abspath(__file__)), "..", "..")
        view_generators_path = os.path.join(ml_dir, "view_generators")
        if view_generators_path not in sys.path:
            sys.path.insert(0, view_generators_path)
        
        from graphic_results import mostrar_graficos_resultados
        caminho_graficos = mostrar_graficos_resultados(modelo, X, y, X_test_scaled, y_test, nome_dataset)
    except ImportError as e:
        print(f"‚ùå Erro ao importar graphic_results: {e}")
        caminho_graficos = "Gr√°ficos n√£o dispon√≠veis"
    except Exception as e:
        print(f"‚ùå Erro ao gerar gr√°ficos: {e}")
        caminho_graficos = "Erro na gera√ß√£o de gr√°ficos"
    
    # Salvar resultados do treinamento
    caminho_resultados = salvar_resultados_treinamento(y_test, y_pred, accuracy, nome_dataset)
    
    # Salvar modelo
    salvar_modelo_final(modelo, scaler, nome_dataset)
    
    print(f"\n‚úÖ CLASSIFICA√á√ÉO CONCLU√çDA COM SUCESSO!")
    print(f"üéØ Acur√°cia final: {accuracy:.1%}")
    print(f"üìä Gr√°ficos: {caminho_graficos}")
    print(f"üìã Resultados: {caminho_resultados}")
    
    print(f"\nüëã Sistema finalizado com sucesso!")


if __name__ == "__main__":
    main()